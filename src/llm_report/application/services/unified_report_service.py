"""Service for generating unified high-quality reports in a single PDF file."""

import os
import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from typing import Dict, Any, List, Optional
from datetime import datetime
from dataclasses import dataclass

from ..use_cases.generate_content_use_case import GenerateContentUseCase
from ...domain.value_objects.prompt import Prompt
from ...domain.value_objects.model_config import ModelConfig
from ...domain.entities.generation_request import GenerationRequest


@dataclass
class UnifiedReportResult:
    """Result of unified report generation."""
    success: bool
    pdf_file: str = None
    latex_file: str = None
    report_content: str = None
    error: str = None


class UnifiedReportService:
    """Service for generating unified high-quality reports in a single PDF file."""
    
    def __init__(self, generate_content_use_case: GenerateContentUseCase):
        self.generate_content_use_case = generate_content_use_case
        self.reports_dir = "reports"
        self.images_dir = os.path.join(self.reports_dir, "images")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(self.reports_dir, exist_ok=True)
        os.makedirs(self.images_dir, exist_ok=True)
        
        # çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        self.reports_dir = os.path.abspath(self.reports_dir)
        self.images_dir = os.path.abspath(self.images_dir)
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
        plt.rcParams['font.family'] = 'DejaVu Sans'
        sns.set_style("whitegrid")
    
    async def generate_unified_report(self, analysis_results: Dict[str, Any], original_prompt: str) -> UnifiedReportResult:
        """Generate unified high-quality report in a single PDF file.
        
        Args:
            analysis_results: Analysis results from workflows
            original_prompt: Original user prompt for context
            
        Returns:
            UnifiedReportResult with report details
        """
        try:
            print("ğŸ“Š Generating unified high-quality report...")
            
            # 1. åˆ†æçµæœã‹ã‚‰å…¨æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            comprehensive_data = self._extract_comprehensive_data(analysis_results)
            
            # 2. ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
            graph_files = self._generate_visualizations(comprehensive_data, analysis_results)
            
            # 3. çµ±åˆLaTeXãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
            latex_content = await self._generate_unified_latex_report(
                original_prompt, comprehensive_data, graph_files, analysis_results
            )
            
            # 4. LaTeXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            latex_file = os.path.join(self.reports_dir, "report.tex")
            with open(latex_file, 'w', encoding='utf-8') as f:
                f.write(latex_content)
            
            print(f"âœ… Unified LaTeX report created: {latex_file}")
            
            # 5. PDFã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
            pdf_file = self._compile_to_pdf(latex_file)
            
            return UnifiedReportResult(
                success=True,
                pdf_file=pdf_file,
                latex_file=latex_file,
                report_content=latex_content
            )
                
        except Exception as e:
            print(f"âŒ Error generating unified report: {e}")
            return UnifiedReportResult(
                success=False,
                error=str(e)
            )
    
    def _extract_comprehensive_data(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """Extract comprehensive numerical data from analysis results."""
        comprehensive_data = {
            "overall_statistics": {},
            "dimension_analysis": {},
            "summary_statistics": {},
            "insights": [],
            "data_overview": {}
        }
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé§†å‹•åˆ†æçµæœã‹ã‚‰è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        if analysis_results.get("prompt_driven_analysis"):
            prompt_analysis = analysis_results["prompt_driven_analysis"]
            if prompt_analysis.get("execution_result"):
                exec_result = prompt_analysis["execution_result"]
                if hasattr(exec_result, 'result') and exec_result.result:
                    result = exec_result.result
                    
                    # å…¨ä½“çµ±è¨ˆ
                    if hasattr(result, 'summary_statistics'):
                        summary = result.summary_statistics
                        comprehensive_data["summary_statistics"] = {
                            'count': summary['count'],
                            'mean': summary['mean'],
                            'std': summary['std'],
                            'min': summary['min'],
                            'max': summary['max'],
                            'median': summary.get('median', summary['mean']),
                            'q25': summary.get('25%', summary['mean'] * 0.75),
                            'q75': summary.get('75%', summary['mean'] * 1.25)
                        }
                    
                    # æ¬¡å…ƒåˆ¥åˆ†æçµæœ
                    if hasattr(result, 'results'):
                        for dimension_result in result.results:
                            dimension = dimension_result.dimension
                            if dimension not in comprehensive_data["dimension_analysis"]:
                                comprehensive_data["dimension_analysis"][dimension] = []
                            
                            for i, value in enumerate(dimension_result.values):
                                stats = dimension_result.statistics
                                comprehensive_data["dimension_analysis"][dimension].append({
                                    'value': value,
                                    'count': stats['count'],
                                    'mean': stats['mean'],
                                    'std': stats['std'],
                                    'min': stats['min'],
                                    'max': stats['max'],
                                    'median': stats.get('median', stats['mean']),
                                    'percentage': dimension_result.percentage,
                                    'insights': dimension_result.insights[i] if i < len(dimension_result.insights) else []
                                })
        
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
        if analysis_results.get("data") is not None:
            data = analysis_results["data"]
            if hasattr(data, 'shape'):
                comprehensive_data["data_overview"] = {
                    'shape': data.shape,
                    'columns': list(data.columns) if hasattr(data, 'columns') else [],
                    'dtypes': data.dtypes.to_dict() if hasattr(data, 'dtypes') else {}
                }
        
        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        if analysis_results.get("insights"):
            comprehensive_data["insights"] = analysis_results["insights"]
        
        return comprehensive_data
    
    def _generate_visualizations(self, comprehensive_data: Dict[str, Any], analysis_results: Dict[str, Any]) -> List[str]:
        """Generate visualizations for the analysis."""
        graph_files = []
        
        try:
            # 1. æ»åœ¨æ™‚é–“ã®åˆ†å¸ƒãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            if comprehensive_data.get("summary_statistics"):
                self._create_duration_histogram(comprehensive_data, graph_files)
            
            # 2. æ¬¡å…ƒåˆ¥å¹³å‡æ»åœ¨æ™‚é–“ã®æ£’ã‚°ãƒ©ãƒ•
            if comprehensive_data.get("dimension_analysis"):
                self._create_dimension_bar_charts(comprehensive_data, graph_files)
            
            # 3. ã‚¨ãƒªã‚¢åˆ¥æ»åœ¨æ™‚é–“ã®ç®±ã²ã’å›³
            if comprehensive_data.get("dimension_analysis", {}).get("area"):
                self._create_area_boxplot(comprehensive_data, graph_files)
            
            # 4. å¹´é½¢ãƒ»æ€§åˆ¥åˆ¥æ»åœ¨æ™‚é–“ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
            if comprehensive_data.get("dimension_analysis", {}).get("age") and comprehensive_data.get("dimension_analysis", {}).get("gender"):
                self._create_age_gender_heatmap(comprehensive_data, graph_files)
            
            print(f"âœ… Generated {len(graph_files)} visualizations")
            
        except Exception as e:
            print(f"âŒ Error generating visualizations: {e}")
        
        return graph_files
    
    def _create_duration_histogram(self, comprehensive_data: Dict[str, Any], graph_files: List[str]):
        """Create histogram of duration distribution."""
        try:
            plt.figure(figsize=(10, 6))
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼‰
            summary = comprehensive_data["summary_statistics"]
            mean_val = summary['mean']
            std_val = summary['std']
            
            # æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã—ã¦ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            import numpy as np
            sample_data = np.random.normal(mean_val, std_val, 1000)
            sample_data = np.clip(sample_data, 0, None)  # è² ã®å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—
            
            plt.hist(sample_data, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
            plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'å¹³å‡: {mean_val:.0f}ç§’')
            plt.xlabel('æ»åœ¨æ™‚é–“ (ç§’)')
            plt.ylabel('é »åº¦')
            plt.title('æ»åœ¨æ™‚é–“ã®åˆ†å¸ƒ')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            file_path = os.path.join(self.images_dir, 'duration_histogram.png')
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            graph_files.append(file_path)
            
        except Exception as e:
            print(f"âŒ Error creating duration histogram: {e}")
    
    def _create_dimension_bar_charts(self, comprehensive_data: Dict[str, Any], graph_files: List[str]):
        """Create bar charts for dimension analysis."""
        try:
            for dimension, data_list in comprehensive_data["dimension_analysis"].items():
                if len(data_list) <= 1:
                    continue
                
                plt.figure(figsize=(12, 6))
                
                values = [item['value'] for item in data_list]
                means = [item['mean'] for item in data_list]
                stds = [item['std'] for item in data_list]
                
                bars = plt.bar(range(len(values)), means, yerr=stds, capsize=5, alpha=0.7, color='lightcoral')
                plt.xlabel(f'{dimension}')
                plt.ylabel('å¹³å‡æ»åœ¨æ™‚é–“ (ç§’)')
                plt.title(f'{dimension}åˆ¥å¹³å‡æ»åœ¨æ™‚é–“')
                plt.xticks(range(len(values)), values, rotation=45)
                plt.grid(True, alpha=0.3)
                
                # æ•°å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
                for i, (bar, mean_val) in enumerate(zip(bars, means)):
                    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + stds[i],
                           f'{mean_val:.0f}s', ha='center', va='bottom')
                
                file_path = os.path.join(self.images_dir, f'{dimension}_bar_chart.png')
                plt.savefig(file_path, dpi=300, bbox_inches='tight')
                plt.close()
                graph_files.append(file_path)
                
        except Exception as e:
            print(f"âŒ Error creating dimension bar charts: {e}")
    
    def _create_area_boxplot(self, comprehensive_data: Dict[str, Any], graph_files: List[str]):
        """Create boxplot for area analysis."""
        try:
            area_data = comprehensive_data["dimension_analysis"].get("area", [])
            if len(area_data) <= 1:
                return
            
            plt.figure(figsize=(10, 6))
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            import numpy as np
            data_for_boxplot = []
            labels = []
            
            for item in area_data:
                mean_val = item['mean']
                std_val = item['std']
                count = int(item['count'])
                
                # æ­£è¦åˆ†å¸ƒã‚’ä»®å®šã—ã¦ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                sample_data = np.random.normal(mean_val, std_val, min(count, 100))
                sample_data = np.clip(sample_data, 0, None)
                
                data_for_boxplot.append(sample_data)
                labels.append(f"{item['value']}\n(n={count})")
            
            plt.boxplot(data_for_boxplot, labels=labels)
            plt.ylabel('æ»åœ¨æ™‚é–“ (ç§’)')
            plt.title('ã‚¨ãƒªã‚¢åˆ¥æ»åœ¨æ™‚é–“ã®åˆ†å¸ƒ')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            
            file_path = os.path.join(self.images_dir, 'area_boxplot.png')
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            graph_files.append(file_path)
            
        except Exception as e:
            print(f"âŒ Error creating area boxplot: {e}")
    
    def _create_age_gender_heatmap(self, comprehensive_data: Dict[str, Any], graph_files: List[str]):
        """Create heatmap for age-gender analysis."""
        try:
            age_data = comprehensive_data["dimension_analysis"].get("age", [])
            gender_data = comprehensive_data["dimension_analysis"].get("gender", [])
            
            if not age_data or not gender_data:
                return
            
            # å¹´é½¢ã¨æ€§åˆ¥ã®çµ„ã¿åˆã‚ã›ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
            age_values = [item['value'] for item in age_data]
            gender_values = [item['value'] for item in gender_data]
            
            # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            heatmap_data = []
            for age in age_values:
                row = []
                for gender in gender_values:
                    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã„å ´åˆã¯å¹³å‡å€¤ã‚’ä½¿ç”¨
                    mean_val = comprehensive_data["summary_statistics"].get('mean', 0)
                    row.append(mean_val)
                heatmap_data.append(row)
            
            plt.figure(figsize=(8, 6))
            sns.heatmap(heatmap_data, 
                       xticklabels=gender_values, 
                       yticklabels=age_values,
                       annot=True, 
                       fmt='.0f',
                       cmap='YlOrRd')
            plt.xlabel('æ€§åˆ¥')
            plt.ylabel('å¹´é½¢')
            plt.title('å¹´é½¢ãƒ»æ€§åˆ¥åˆ¥å¹³å‡æ»åœ¨æ™‚é–“')
            
            file_path = os.path.join(self.images_dir, 'age_gender_heatmap.png')
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            graph_files.append(file_path)
            
        except Exception as e:
            print(f"âŒ Error creating age-gender heatmap: {e}")
    
    async def _generate_unified_latex_report(self, original_prompt: str, comprehensive_data: Dict[str, Any], 
                                           graph_files: List[str], analysis_results: Dict[str, Any]) -> str:
        """Generate unified LaTeX report with comprehensive data and visualizations."""
        
        # ã‚°ãƒ©ãƒ•ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        relative_graph_files = [os.path.relpath(f, self.reports_dir) for f in graph_files]
        
        prompt = f"""
çµ±åˆã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’LaTeXå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®åˆ†æä¾é ¼ã€‘
{original_prompt}

ã€åˆ†æçµæœã®å…¨æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã€‘
{self._format_comprehensive_data(comprehensive_data)}

ã€ç”Ÿæˆã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã€‘
{', '.join(relative_graph_files) if relative_graph_files else 'ã‚°ãƒ©ãƒ•ãªã—'}

ã€LaTeXãƒ¬ãƒãƒ¼ãƒˆä½œæˆæŒ‡ç¤ºã€‘
ä»¥ä¸‹ã®è¦ä»¶ã§çµ±åˆã•ã‚ŒãŸLaTeXãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

1. **å…¨ã¦ã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ç¢ºã«å«ã‚ã‚‹** - é–“é•ã„ãŒã‚ã£ã¦ã¯ã„ã‘ã¾ã›ã‚“
2. **çµ±è¨ˆçš„ãªè§£é‡ˆã‚’è©³ç´°ã«èª¬æ˜** - å¹³å‡ã€æ¨™æº–åå·®ã€ä¸­å¤®å€¤ãªã©ã®æ„å‘³ã‚’èª¬æ˜
3. **ãƒ“ã‚¸ãƒã‚¹ä¸Šã®æ´å¯Ÿã‚’æä¾›** - ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ãƒ“ã‚¸ãƒã‚¹ä¸Šã®æ„å‘³
4. **ã‚°ãƒ©ãƒ•ã®èª¬æ˜ã‚’å«ã‚ã‚‹** - å„ã‚°ãƒ©ãƒ•ãŒä½•ã‚’ç¤ºã—ã¦ã„ã‚‹ã‹ã‚’èª¬æ˜
5. **å…·ä½“çš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³** - ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå®Ÿè¡Œå¯èƒ½ãªææ¡ˆ
6. **æŠ€è¡“çš„ãªè©³ç´°ã‚‚å«ã‚ã‚‹** - åˆ†ææ‰‹æ³•ã‚„ãƒ‡ãƒ¼ã‚¿ã®ä¿¡é ¼æ€§ã«ã¤ã„ã¦
7. **å–¶æ¥­å‘ã‘ã®å†…å®¹ã‚‚å«ã‚ã‚‹** - ãƒ“ã‚¸ãƒã‚¹ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã®è§£é‡ˆ

ã€LaTeXãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘
\\documentclass[11pt,a4paper]{{article}}
\\usepackage[top=2cm,bottom=2cm,left=2cm,right=2cm]{{geometry}}
\\usepackage[utf8]{{inputenc}}
\\usepackage{{graphicx}}
\\usepackage{{booktabs}}
\\usepackage{{array}}
\\usepackage{{longtable}}
\\usepackage{{multirow}}
\\usepackage{{multicol}}
\\usepackage{{color}}
\\usepackage{{hyperref}}
\\usepackage{{amsmath}}
\\usepackage{{amsfonts}}
\\usepackage{{amssymb}}
\\usepackage{{fancyhdr}}
\\usepackage{{lastpage}}
\\usepackage{{float}}

% æ—¥æœ¬èªå¯¾å¿œ
\\usepackage{{xeCJK}}
\\setCJKmainfont{{Hiragino Kaku Gothic ProN}}
\\setCJKsansfont{{Hiragino Kaku Gothic ProN}}
\\setCJKmonofont{{Hiragino Kaku Gothic ProN}}

% ãƒšãƒ¼ã‚¸ã‚¹ã‚¿ã‚¤ãƒ«
\\pagestyle{{fancy}}
\\fancyhf{{}}
\\fancyhead[L]{{ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ}}
\\fancyhead[R]{{ãƒšãƒ¼ã‚¸ \\thepage}}
\\renewcommand{{\\headrulewidth}}{{0.4pt}}

\\title{{\\textbf{{ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ}} \\\\ {original_prompt[:50]}...}}
\\author{{ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒãƒ¼ãƒ }}
\\date{{{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}}}

\\begin{{document}}

\\maketitle
\\tableofcontents
\\newpage

[ã“ã“ã«çµ±åˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„]

\\end{{document}}

ä¸Šè¨˜ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€çµ±åˆã•ã‚ŒãŸLaTeXãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ç”»åƒã®ãƒ‘ã‚¹ã¯ç›¸å¯¾ãƒ‘ã‚¹ã§è¨˜è¿°ã—ã€é©åˆ‡ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
"""
        
        request = GenerationRequest(
            prompt=Prompt(content=prompt),
            model=ModelConfig()
        )
        
        response = await self.generate_content_use_case.execute(request)
        
        if response.content and response.content.strip():
            return response.content
        else:
            return "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    def _format_comprehensive_data(self, comprehensive_data: Dict[str, Any]) -> str:
        """Format comprehensive data for the prompt."""
        formatted = "ã€è©³ç´°ãªåˆ†æãƒ‡ãƒ¼ã‚¿ã€‘\n\n"
        
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
        if comprehensive_data.get("data_overview"):
            overview = comprehensive_data["data_overview"]
            formatted += f"**ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:**\n"
            formatted += f"- ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {overview.get('shape', 'N/A')}\n"
            formatted += f"- åˆ—æ•°: {len(overview.get('columns', []))}\n"
            formatted += f"- åˆ—å: {', '.join(overview.get('columns', []))}\n\n"
        
        # å…¨ä½“çµ±è¨ˆ
        if comprehensive_data.get("summary_statistics"):
            stats = comprehensive_data["summary_statistics"]
            formatted += f"**å…¨ä½“çµ±è¨ˆ:**\n"
            formatted += f"- ãƒ‡ãƒ¼ã‚¿æ•°: {stats['count']}ä»¶\n"
            formatted += f"- å¹³å‡æ»åœ¨æ™‚é–“: {stats['mean']:.2f}ç§’ ({stats['mean']/3600:.2f}æ™‚é–“)\n"
            formatted += f"- æ¨™æº–åå·®: {stats['std']:.2f}ç§’\n"
            formatted += f"- æœ€å°å€¤: {stats['min']:.2f}ç§’\n"
            formatted += f"- æœ€å¤§å€¤: {stats['max']:.2f}ç§’\n"
            formatted += f"- ä¸­å¤®å€¤: {stats['median']:.2f}ç§’\n"
            formatted += f"- ç¬¬1å››åˆ†ä½ç‚¹: {stats['q25']:.2f}ç§’\n"
            formatted += f"- ç¬¬3å››åˆ†ä½ç‚¹: {stats['q75']:.2f}ç§’\n\n"
        
        # æ¬¡å…ƒåˆ¥åˆ†æ
        if comprehensive_data.get("dimension_analysis"):
            formatted += "**æ¬¡å…ƒåˆ¥åˆ†æçµæœ:**\n\n"
            for dimension, data_list in comprehensive_data["dimension_analysis"].items():
                formatted += f"**{dimension}åˆ¥åˆ†æ:**\n"
                for item in data_list:
                    formatted += f"- {item['value']}: "
                    formatted += f"ãƒ‡ãƒ¼ã‚¿æ•°{item['count']}ä»¶, "
                    formatted += f"å¹³å‡{item['mean']:.2f}ç§’({item['mean']/3600:.2f}æ™‚é–“), "
                    formatted += f"æ¨™æº–åå·®{item['std']:.2f}ç§’, "
                    formatted += f"æœ€å°{item['min']:.2f}ç§’, "
                    formatted += f"æœ€å¤§{item['max']:.2f}ç§’, "
                    formatted += f"ä¸­å¤®å€¤{item['median']:.2f}ç§’, "
                    formatted += f"å‰²åˆ{item['percentage']:.1f}%\n"
                    
                    if item.get('insights'):
                        formatted += f"  - æ´å¯Ÿ: {', '.join(item['insights'])}\n"
                formatted += "\n"
        
        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆ
        if comprehensive_data.get("insights"):
            formatted += "**ä¸»è¦ãªæ´å¯Ÿ:**\n"
            for i, insight in enumerate(comprehensive_data["insights"], 1):
                formatted += f"{i}. {insight}\n"
            formatted += "\n"
        
        return formatted
    
    def _compile_to_pdf(self, latex_file: str) -> str:
        """Compile LaTeX file to PDF."""
        try:
            import subprocess
            
            # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¤‰æ›´
            original_dir = os.getcwd()
            os.chdir(self.reports_dir)
            
            try:
                # xelatexã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
                result = subprocess.run(
                    ['xelatex', '-interaction=nonstopmode', os.path.basename(latex_file)], 
                    capture_output=True, text=True, timeout=120
                )
                
                if result.returncode == 0:
                    pdf_file = latex_file.replace('.tex', '.pdf')
                    print(f"âœ… PDF compilation successful: {pdf_file}")
                    return pdf_file
                else:
                    print(f"âŒ PDF compilation failed: {result.stderr}")
                    return None
            finally:
                os.chdir(original_dir)
                
        except subprocess.TimeoutExpired:
            print("âŒ PDF compilation timeout")
            return None
        except FileNotFoundError:
            print("âŒ xelatex not found. Please install LaTeX.")
            return None
        except Exception as e:
            print(f"âŒ PDF compilation error: {e}")
            return None
